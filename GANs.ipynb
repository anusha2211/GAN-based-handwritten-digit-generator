{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzXDrQ8Ql3M9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBdHe0TamDQT",
        "outputId": "d1100c72-aec7-48b4-cdca-2696fe256e7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "LBFL50qLmD83",
        "outputId": "ab583d69-dc1e-466a-bec5-89dc6ac2c552"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f80e7b094d0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(train_images[1], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXZiaL9-mGRs"
      },
      "outputs": [],
      "source": [
        "# Normalization\n",
        "train_images= (train_images-127.5)/127.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "hVjHpGrwmP9M",
        "outputId": "c4e74056-34c3-4590-a689-d9578d1bd44d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f80e7a8a5d0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(train_images[1],cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ8_OrxomR_I",
        "outputId": "d2a39c7e-9985-463d-aff1-b62bb93dbd4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Expanding dimensions\n",
        "train_images = train_images.reshape(train_images.shape[0],28,28,1)\n",
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQzvVxkSmVyv"
      },
      "outputs": [],
      "source": [
        "# Defining parameters\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGT6tILfmXNS"
      },
      "outputs": [],
      "source": [
        "# Batchwise shuffling of the dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gydjGEsmaiE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSQuBwW0mcHI"
      },
      "source": [
        "### Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzJ4C-UUmjkQ"
      },
      "outputs": [],
      "source": [
        "#CNN model\n",
        "def discriminator():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Conv2D(7,(3,3),padding='same',input_shape=(28,28,1)))\n",
        "  model.add(tf.keras.layers.Conv2D(7,(3,3),padding='same'))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(50,activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyzCjMZZnY3d"
      },
      "outputs": [],
      "source": [
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpQGZ2Q4qYU9"
      },
      "outputs": [],
      "source": [
        "# loss function for the discriminator\n",
        "def discriminator_loss(real_predictions, fake_predictions):\n",
        "  real_predictions = tf.sigmoid(real_predictions)\n",
        "  fake_predictions = tf.sigmoid(fake_predictions)\n",
        "\n",
        "  #computing binary cross entropy loss\n",
        "  real_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(real_predictions), real_predictions)\n",
        "  fake_loss = tf.keras.losses.binary_crossentropy(tf.zeros_like(fake_predictions),fake_predictions)\n",
        "\n",
        "  #returning final losses\n",
        "  if real_loss.shape == fake_loss.shape:\n",
        "    return real_loss+fake_loss\n",
        "  else:\n",
        "    return fake_loss+0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV8iZriAqkm_",
        "outputId": "e1c62a8d-0a19-46f8-9468-3fd9be90de4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 7)         70        \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 7)         448       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 5488)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                274450    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 275,019\n",
            "Trainable params: 275,019\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator().summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtXryqecqoGL"
      },
      "outputs": [],
      "source": [
        "def generator():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(7*7*256,input_shape =(100,)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dense(7*7*256))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Reshape( (7,7,256) ))\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same'))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph435wj6cu2i"
      },
      "outputs": [],
      "source": [
        "def generator_loss(fake_predictions):\n",
        "  fake_predictions = tf.sigmoid(fake_predictions)\n",
        "  fake_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(fake_predictions),fake_predictions)\n",
        "  return fake_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdma-Oxac77c"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iynpdgt5c8lp"
      },
      "outputs": [],
      "source": [
        "generator_model= generator()\n",
        "discriminator_model = discriminator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FE85xc-c_M4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpHrwjzAdAQ3"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QJARHSJdB23"
      },
      "outputs": [],
      "source": [
        "def train(data, epochs):\n",
        "  for i in range(epochs):\n",
        "    for images in data:\n",
        "      images = tf.cast(images,tf.dtypes.float32)\n",
        "      train_step(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IghDvgaEdEiO"
      },
      "outputs": [],
      "source": [
        "def train_step(images):\n",
        "  noise = np.random.randn(BATCH_SIZE, 100).astype('float32')\n",
        "  # batchwise training\n",
        "  with tf.GradientTape() as generator_tape, tf.GradientTape() as discriminator_tape:\n",
        "        # Create fake images\n",
        "        generated_images = generator_model(noise)\n",
        "        # Pass fake images through the discriminator\n",
        "        generator_output = discriminator_model(generated_images)\n",
        "        # Pass real images through the discriminator\n",
        "        real_output = discriminator_model(images)\n",
        "\n",
        "        # calculate individual losses\n",
        "        gen_loss = generator_loss(generator_output)\n",
        "        disc_loss = discriminator_loss(real_output, generator_output)\n",
        "\n",
        "        # Calculate gradients of loss functions\n",
        "        generator_gradients= generator_tape.gradient(gen_loss,generator_model.trainable_variables)\n",
        "        discriminator_gradients = discriminator_tape.gradient(disc_loss, discriminator_model.trainable_variables)\n",
        "\n",
        "        # Optimise\n",
        "        generator_optimizer.apply_gradients(zip(generator_gradients, generator_model.trainable_variables))\n",
        "        discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator_model.trainable_variables))\n",
        "\n",
        "        print(\"Generator Loss: \",np.mean(gen_loss))\n",
        "        print(\"Discriminator Loss: \",np.mean(disc_loss))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNyjZbTkdKg7",
        "outputId": "8ceb39b2-9e46-4c51-8536-58201452181d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.40359\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.9843235\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804637\n",
            "Generator Loss:  5.8446097\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.82286\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744741\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.144216\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924428\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223905\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104115\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122337\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703069\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.8645315\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  5.0613117\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  6.9894295\n",
            "Discriminator Loss:  8.385368\n",
            "Generator Loss:  6.3868933\n",
            "Discriminator Loss:  8.984323\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122336\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703069\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924427\n",
            "Generator Loss:  6.3868933\n",
            "Discriminator Loss:  8.9843235\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.62495\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  6.868922\n",
            "Discriminator Loss:  8.505159\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002545\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242127\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242127\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.9843235\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122336\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583279\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122336\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104115\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421814\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762963\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343697\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343696\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583278\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223905\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104115\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044218\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804636\n",
            "Generator Loss:  6.1458783\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223905\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.40359\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044218\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343696\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164009\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804636\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463487\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.9843235\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361918\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104115\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044218\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164009\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002545\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744741\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762963\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762963\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984323\n",
            "Generator Loss:  5.4830866\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  5.0613117\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164009\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.8645315\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924427\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104114\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002545\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242127\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.40359\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762963\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.7447405\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744741\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762963\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.9843235\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  6.6279073\n",
            "Discriminator Loss:  8.744741\n",
            "Generator Loss:  5.784355\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684845\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044218\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164009\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002546\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044218\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044218\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.62495\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122336\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762963\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762963\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.9843235\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.7447405\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924427\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182231\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044218\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762963\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421814\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164009\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164009\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164009\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804636\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164009\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684845\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104114\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164008\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044218\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302022\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164009\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481708\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.402021\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104114\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  7.0496836\n",
            "Discriminator Loss:  8.325472\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.8645315\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044217\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.6249485\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  6.8086686\n",
            "Discriminator Loss:  8.565054\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684845\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182231\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.98943\n",
            "Discriminator Loss:  8.385367\n",
            "Generator Loss:  6.868922\n",
            "Discriminator Loss:  8.505157\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984323\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.40359\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.40359\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.0613117\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223905\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804636\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044217\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924427\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044218\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  4.760042\n",
            "Discriminator Loss:  10.601499\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.6249485\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104114\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.40359\n",
            "Generator Loss:  4.458774\n",
            "Discriminator Loss:  10.900976\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804636\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.0613117\n",
            "Discriminator Loss:  10.302022\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044218\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.6015\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804635\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164008\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044217\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924426\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.74474\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804635\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.40359\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164008\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.40359\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223905\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924426\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.683275\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  4.639535\n",
            "Discriminator Loss:  10.721289\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.8446097\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.3023257\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.40359\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.74474\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.8446097\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  6.6279073\n",
            "Discriminator Loss:  8.74474\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  7.170191\n",
            "Discriminator Loss:  8.205681\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924426\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.74474\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044217\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  7.0496836\n",
            "Discriminator Loss:  8.325471\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.567654\n",
            "Discriminator Loss:  8.804635\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924426\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984321\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481708\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  6.868922\n",
            "Discriminator Loss:  8.505157\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804635\n",
            "Generator Loss:  4.820297\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.74474\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.74474\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164008\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.40359\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924426\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164008\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044217\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.8446097\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.74474\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.3625803\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.4830866\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.688161\n",
            "Discriminator Loss:  8.684845\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164008\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.74474\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.3625803\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104112\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  6.5073996\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.28223\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984321\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684844\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924426\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781185\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  6.9291763\n",
            "Discriminator Loss:  8.445262\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924426\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984321\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.86453\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684844\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.6249485\n",
            "Generator Loss:  4.5792813\n",
            "Discriminator Loss:  10.781185\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104112\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  6.7484145\n",
            "Discriminator Loss:  8.6249485\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  6.567654\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  6.808668\n",
            "Discriminator Loss:  8.565053\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  6.868922\n",
            "Discriminator Loss:  8.505157\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  4.760042\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481708\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104112\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  6.9291763\n",
            "Discriminator Loss:  8.445262\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984321\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.8086686\n",
            "Discriminator Loss:  8.565052\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  7.049683\n",
            "Discriminator Loss:  8.325471\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.3266387\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.62338\n",
            "Generator Loss:  6.6279073\n",
            "Discriminator Loss:  8.744739\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  6.6279073\n",
            "Discriminator Loss:  8.744739\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.86453\n",
            "Generator Loss:  7.411206\n",
            "Discriminator Loss:  7.9660983\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781184\n",
            "Generator Loss:  5.8446097\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601499\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104112\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  6.567654\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  6.688161\n",
            "Discriminator Loss:  8.684843\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104112\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.984321\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  6.3266387\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  6.9894295\n",
            "Discriminator Loss:  8.385366\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744739\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.86453\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.688161\n",
            "Discriminator Loss:  8.684843\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.868922\n",
            "Discriminator Loss:  8.5051565\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  6.808669\n",
            "Discriminator Loss:  8.565052\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  6.98943\n",
            "Discriminator Loss:  8.3853655\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.6249485\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  6.8086686\n",
            "Discriminator Loss:  8.565052\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  7.230444\n",
            "Discriminator Loss:  8.145784\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.30202\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104112\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  4.760043\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661393\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.3023257\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104112\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684843\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  7.0496836\n",
            "Discriminator Loss:  8.32547\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.204111\n",
            "Generator Loss:  6.98943\n",
            "Discriminator Loss:  8.385366\n",
            "Generator Loss:  6.8086686\n",
            "Discriminator Loss:  8.565052\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  6.9894295\n",
            "Discriminator Loss:  8.3853655\n",
            "Generator Loss:  6.688161\n",
            "Discriminator Loss:  8.684843\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.624948\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.567654\n",
            "Discriminator Loss:  8.804633\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  6.8086686\n",
            "Discriminator Loss:  8.565052\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  4.639535\n",
            "Discriminator Loss:  10.721289\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  7.2906985\n",
            "Discriminator Loss:  8.085889\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.624947\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.624947\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.624948\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.624948\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  7.170191\n",
            "Discriminator Loss:  8.205679\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  5.784355\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.688161\n",
            "Discriminator Loss:  8.684843\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.86453\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.567654\n",
            "Discriminator Loss:  8.804633\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.8086686\n",
            "Discriminator Loss:  8.565052\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541601\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541602\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421811\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.8086686\n",
            "Discriminator Loss:  8.565052\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661392\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.803066\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.86453\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  7.0496836\n",
            "Discriminator Loss:  8.32547\n",
            "Generator Loss:  5.3023257\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.624948\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.6279073\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.30202\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.8446097\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  5.8446097\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684843\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.784355\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302019\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  7.350952\n",
            "Discriminator Loss:  8.025992\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.0613117\n",
            "Discriminator Loss:  10.30202\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684843\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.784355\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.30202\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.688161\n",
            "Discriminator Loss:  8.684842\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302019\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.3023257\n",
            "Discriminator Loss:  10.062437\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481706\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822855\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942646\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.904633\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.30202\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.8446097\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  6.98943\n",
            "Discriminator Loss:  8.3853655\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  6.02537\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804633\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463483\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  6.868922\n",
            "Discriminator Loss:  8.505156\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661392\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942646\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062437\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164005\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661392\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  4.639535\n",
            "Discriminator Loss:  10.721288\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804633\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302019\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.9291763\n",
            "Discriminator Loss:  8.445261\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541601\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.6279073\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781183\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  7.290698\n",
            "Discriminator Loss:  8.085888\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.3868933\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164005\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  7.0496836\n",
            "Discriminator Loss:  8.32547\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781183\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182228\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.3868933\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583273\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  6.98943\n",
            "Discriminator Loss:  8.385365\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122333\n",
            "Generator Loss:  6.3868933\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302019\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.02537\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182228\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601497\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924423\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804633\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  4.760043\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822855\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062437\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.102544\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541601\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062437\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164005\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481706\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942646\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002542\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583273\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062437\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002542\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122333\n",
            "Generator Loss:  5.784355\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.688161\n",
            "Discriminator Loss:  8.684842\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361915\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182228\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164005\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463483\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463483\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343692\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463483\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541601\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804633\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302019\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.721289\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481706\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062437\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343692\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182228\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463483\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182228\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  6.868922\n",
            "Discriminator Loss:  8.505156\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481706\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661392\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804633\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182228\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122333\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684842\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541601\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182228\n",
            "Generator Loss:  7.2906985\n",
            "Discriminator Loss:  8.085888\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463483\n",
            "Generator Loss:  6.02537\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361915\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781183\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.10411\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  6.688161\n",
            "Discriminator Loss:  8.684843\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804633\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.3023257\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463483\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  6.98943\n",
            "Discriminator Loss:  8.385365\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062437\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302019\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.563484\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.567654\n",
            "Discriminator Loss:  8.804633\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  5.4830866\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.868922\n",
            "Discriminator Loss:  8.505156\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463483\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661392\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302019\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  5.4830866\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.688161\n",
            "Discriminator Loss:  8.684842\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182228\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223901\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481706\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044214\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661392\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703064\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661392\n",
            "Generator Loss:  6.868922\n",
            "Discriminator Loss:  8.505156\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002542\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164005\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.567654\n",
            "Discriminator Loss:  8.804633\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.688161\n",
            "Discriminator Loss:  8.684842\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062437\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302019\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343692\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481706\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062437\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343692\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242124\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164005\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343692\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541601\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942646\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002542\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062437\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343692\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684842\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463483\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804633\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361915\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463483\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781183\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.624947\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044214\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  6.688161\n",
            "Discriminator Loss:  8.684842\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  6.868922\n",
            "Discriminator Loss:  8.505156\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.10411\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822855\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122333\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182228\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343691\n",
            "Generator Loss:  6.5073996\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361915\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.8827505\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182228\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463483\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044214\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804633\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  10.042648\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164005\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044214\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.624947\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.10411\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  6.868922\n",
            "Discriminator Loss:  8.505156\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  4.3985205\n",
            "Discriminator Loss:  10.96087\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.8446097\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002542\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302019\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044214\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182228\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223901\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343692\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044214\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481706\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463483\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822855\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242124\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583273\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361915\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242124\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684841\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541601\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343692\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942646\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164005\n",
            "Generator Loss:  4.458774\n",
            "Discriminator Loss:  10.900974\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942646\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583274\n",
            "Generator Loss:  4.5792813\n",
            "Discriminator Loss:  10.781183\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.8827505\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942646\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182228\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942646\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703065\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062437\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302019\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164005\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  4.4587746\n",
            "Discriminator Loss:  10.900974\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002542\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062437\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283796\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804633\n",
            "Generator Loss:  6.146289\n",
            "Discriminator Loss:  9.173004\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  3.2537\n",
            "Discriminator Loss:  12.098884\n",
            "Generator Loss:  3.434461\n",
            "Discriminator Loss:  11.919198\n",
            "Generator Loss:  3.6152225\n",
            "Discriminator Loss:  11.7395115\n",
            "Generator Loss:  3.8562372\n",
            "Discriminator Loss:  11.499931\n",
            "Generator Loss:  3.6152222\n",
            "Discriminator Loss:  11.739513\n",
            "Generator Loss:  4.1575055\n",
            "Discriminator Loss:  11.200455\n",
            "Generator Loss:  4.0369983\n",
            "Discriminator Loss:  11.320246\n",
            "Generator Loss:  4.278013\n",
            "Discriminator Loss:  11.080666\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661398\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.721294\n",
            "Generator Loss:  3.7959836\n",
            "Discriminator Loss:  11.559831\n",
            "Generator Loss:  3.6152222\n",
            "Discriminator Loss:  11.739519\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661401\n",
            "Generator Loss:  4.760043\n",
            "Discriminator Loss:  10.601506\n",
            "Generator Loss:  3.5549686\n",
            "Discriminator Loss:  11.799417\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481718\n",
            "Generator Loss:  4.458774\n",
            "Discriminator Loss:  10.900987\n",
            "Generator Loss:  4.3985205\n",
            "Discriminator Loss:  10.960883\n",
            "Generator Loss:  4.097252\n",
            "Discriminator Loss:  11.260358\n",
            "Generator Loss:  3.434461\n",
            "Discriminator Loss:  11.91921\n",
            "Generator Loss:  4.097252\n",
            "Discriminator Loss:  11.260362\n",
            "Generator Loss:  4.097252\n",
            "Discriminator Loss:  11.260362\n",
            "Generator Loss:  4.338267\n",
            "Discriminator Loss:  11.020781\n",
            "Generator Loss:  4.097252\n",
            "Discriminator Loss:  11.260365\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661406\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361931\n",
            "Generator Loss:  4.3985205\n",
            "Discriminator Loss:  10.960885\n",
            "Generator Loss:  3.675476\n",
            "Discriminator Loss:  11.67963\n",
            "Generator Loss:  3.9164908\n",
            "Discriminator Loss:  11.440049\n",
            "Generator Loss:  3.7357297\n",
            "Discriminator Loss:  11.6197405\n",
            "Generator Loss:  4.338267\n",
            "Discriminator Loss:  11.0207815\n",
            "Generator Loss:  4.3382664\n",
            "Discriminator Loss:  11.0207815\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302038\n",
            "Generator Loss:  4.5792813\n",
            "Discriminator Loss:  10.781201\n",
            "Generator Loss:  4.278013\n",
            "Discriminator Loss:  11.080678\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182249\n",
            "Generator Loss:  3.9164908\n",
            "Discriminator Loss:  11.44005\n"
          ]
        }
      ],
      "source": [
        "train(train_dataset,100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVOLo49XdNGG"
      },
      "outputs": [],
      "source": [
        "test_image_noise = np.random.randn(1,100)\n",
        "generated_test_image = generator_model(test_image_noise)\n",
        "plt.imshow(tf.reshape(generated_test_image,(28,28)),cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPS6pd51dSv6"
      },
      "outputs": [],
      "source": [
        "random_image = np.random.randn(784)\n",
        "random_image = tf.reshape(random_image,(28,28))\n",
        "plt.imshow(random_image,cmap='gray')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}